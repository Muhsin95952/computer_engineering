{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43231d2c-b613-46e4-b946-7ec73ab895a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a simple Neural Network for Handwritten Digit Recognition with the MNIST dataset from Kaggle\n",
    "# Using Jupyter Notebook, Python 3, NumPy and Math\n",
    "\n",
    "# https://www.kaggle.com/competitions/digit-recognizer/overview                      #data I used for training\n",
    "# https://www.kaggle.com/datasets/oddrationale/mnist-in-csv?select=mnist_test.csv    #data I used for testing \n",
    "\n",
    "# https://www.youtube.com/watch?v=w8yWXqWQYmU&t=1667s                                #video I used to understand the math and code\n",
    "# Sidenote to the video: It explains every step very nicely, in a simple and compact way.\n",
    "# Nevertheless I had some issues with the code (even after making sure I corrected the mentioned errors of the video)\n",
    "# and spent hours on debugging it. \n",
    "\n",
    "\n",
    "# We start by importing NumPy, Matplotlib, and Pandas libraries to help us work with numbers,\n",
    "# create visualizations like graphs, and manage data tables, respectively.\n",
    "\n",
    "import numpy as np                  # NumPy for numerical operations\n",
    "import matplotlib.pyplot as plt     # Matplotlib for plotting graphs\n",
    "import pandas as pd                 # Pandas for handling data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ce379c-d67d-44e1-ab3c-5c2586c94fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Pandas to read the data from a CSV file (in this case previously downloaded from Kaggle) located at the specified path.\n",
    "data = pd.read_csv(r\"C:\\Users\\Home\\Documents\\STUDIUM\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43e1faf-d22f-426f-8f9e-f76ec383b214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the \".head\" command displays the first 5 rows of the loaded data to inspect its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47343876-af82-4af8-bae3-bd60aa60b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda DataFrame gets converted into a NumPy Array (from original tabular data structure) so we can do algebra with it\n",
    "data = np.array(data)\n",
    "\n",
    "# m = represents number of rows in the data array; specifically m = number of samples in the dataset\n",
    "# n = represents number of columns; n= number of features plus one (including the label column)\n",
    "m, n = data.shape\n",
    "\n",
    "# shuffels the rows of the data array randomly; to ensure that the data is randomly ordered before splitting it into training and validation sets,\n",
    "# helps prevent any unintentional ordering biases in the data and eliminates the risk of overfitting to the actual data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "\n",
    "# selects a portion of the shuffled data (from index 1000 to the end) to be used as the development set (or validation set)\n",
    "# the \".T\" at the end transposes the array, swapping rows and columns\n",
    "data_dev = data[1000:, :].T\n",
    "\n",
    "# These lines extract the labels (Y_dev) and the features (X_dev) from the development set:\n",
    "# Y_dev is assumed to be the first column of the data_dev array\n",
    "# X_dev contains all other columns (features)\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:]\n",
    "\n",
    "# Following step divides each pixel value in the feature matrix X_dev by 255. \n",
    "# This makes sure all pixel values are between 0 and 1, which is helpful for processing images. (common preprocessing step for image data)\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "# selects the remaining portion of the shuffled data (excluding the validation set) to be used as the training set\n",
    "data_train = data[:1000].T\n",
    "\n",
    "\n",
    "# These lines extract the labels (Y_train) and the features (X_train) from the training set again:\n",
    "# Y_train is assumed to be the first column of the data_train array\n",
    "# X_train contains all other columns (features)\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:]\n",
    "\n",
    "\n",
    "# normalizes the pixel values in the feature matrix X_train (=> devides X_train by 255)\n",
    "X_train = X_train / 255.\n",
    "\n",
    "\n",
    "# Reshape X_train to have the shape (784, 41000)\n",
    "X_train = X_train.reshape(784, -1)\n",
    "\n",
    "\n",
    "# This line calculates the number of training samples (m_train) by extracting the number of rows in the feature matrix X_train. \n",
    "# The underscore _ is used to indicate that we are not interested in the first value returned by X_train.shape, which represents the number of features\n",
    "_, m_train = X_train.shape\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# In summary, this code preprocesses a dataset for machine learning tasks involving image data. \n",
    "# It splits the dataset into training and validation sets, extracts features and labels, shuffles the data,\n",
    "# and normalizes the pixel values of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bf86d7-271a-47b7-b032-87cc27a5ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the funtions we need to train our Neural Network.\n",
    "\n",
    "\n",
    "# This function sets random starting values for the weights and biases used in the neural network.\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "\n",
    "# This activation function takes a number Z as input. If Z is positive, it returns Z itself. \n",
    "# If Z is negative, it returns zero. It basically converts negative numbers to zero while leaving positive numbers unchanged.\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "\n",
    "\n",
    "# This function calculates the probabilities for each class by exponentiating the input values Z, \n",
    "# adjusting them to avoid numerical overflow, and then normalizing them so they sum up to one.\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z))\n",
    "    return exp_Z / exp_Z.sum(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# This function converts class labels into a special format called \"one-hot encoding.\" \n",
    "# It creates an array where each row represents a different class, and each column represents a sample. \n",
    "# If a sample belongs to a class, the corresponding value in that class's row is set to 1; otherwise, it's set to 0.\n",
    "def one_hot(Y):\n",
    "    num_classes = Y.max() + 1\n",
    "    one_hot_Y = np.zeros((num_classes, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "\n",
    "\n",
    "# This function checks each element in the input array Z to see if it's greater than 0. \n",
    "#If it is, it returns True; otherwise, it returns False. In other words, it tells us which elements of Z are positive and which are not.\n",
    "def deriv_ReLU(Z):\n",
    "    return Z > 0\n",
    "    \n",
    "\n",
    "\n",
    "# This function performs forward propagation in a neural network, computing the activations of hidden layers (A1) \n",
    "# and output layer (A2) given the input features (X) and learned parameters (weights W1 and W2, biases b1 and b2), \n",
    "# utilizing Rectified Linear Unit (ReLU) activation for the hidden layer and Softmax activation for the output layer.\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "\n",
    "# This function computes the gradients of the loss function with respect to the parameters (weights and biases) using backward propagation.\n",
    "# It calculates the gradients for both hidden and output layers (dW1, db1, dW2, db2) based on the given input (X), target labels (Y),\n",
    "# activations of the hidden layer (A1) and output layer (A2), and intermediate values (Z1, Z2) computed during forward propagation.\n",
    "def backward_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "\n",
    "# This function updates the parameters (weights and biases) of the neural network using gradient descent to minimize the loss function, \n",
    "# facilitating learning.\n",
    "def update_params(alpha, W1, b1, W2, b2, dW1, db1, dW2, db2):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33552e0e-6e83-496a-a679-026ceef3b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function predicts the class labels for each input sample based on the output activations A2 of the neural network, \n",
    "# selecting the class with the highest probability for each sample.\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# This function calculates the accuracy of the predictions by comparing them with the true labels and dividing the number \n",
    "# of correct predictions by the total number of samples.\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "\n",
    "\n",
    "# This function implements gradient descent to train the neural network. It iteratively updates the parameters (weights and biases)\n",
    "# based on the gradients of the loss function with respect to these parameters. It prints the iteration number and accuracy every 10 iterations.\n",
    "# Finally, it returns the updated parameters.\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(alpha, W1, b1, W2, b2, dW1, db1, dW2, db2)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(\"Accuracy:\", get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f5a2c4-e591-4808-befe-58cee26777ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 0.125\n",
      "Iteration: 10\n",
      "Accuracy: 0.207\n",
      "Iteration: 20\n",
      "Accuracy: 0.29\n",
      "Iteration: 30\n",
      "Accuracy: 0.373\n",
      "Iteration: 40\n",
      "Accuracy: 0.436\n",
      "Iteration: 50\n",
      "Accuracy: 0.51\n",
      "Iteration: 60\n",
      "Accuracy: 0.563\n",
      "Iteration: 70\n",
      "Accuracy: 0.61\n",
      "Iteration: 80\n",
      "Accuracy: 0.651\n",
      "Iteration: 90\n",
      "Accuracy: 0.678\n",
      "Iteration: 100\n",
      "Accuracy: 0.705\n",
      "Iteration: 110\n",
      "Accuracy: 0.729\n",
      "Iteration: 120\n",
      "Accuracy: 0.74\n",
      "Iteration: 130\n",
      "Accuracy: 0.75\n",
      "Iteration: 140\n",
      "Accuracy: 0.761\n",
      "Iteration: 150\n",
      "Accuracy: 0.777\n",
      "Iteration: 160\n",
      "Accuracy: 0.788\n",
      "Iteration: 170\n",
      "Accuracy: 0.796\n",
      "Iteration: 180\n",
      "Accuracy: 0.803\n",
      "Iteration: 190\n",
      "Accuracy: 0.806\n",
      "Iteration: 200\n",
      "Accuracy: 0.815\n",
      "Iteration: 210\n",
      "Accuracy: 0.818\n",
      "Iteration: 220\n",
      "Accuracy: 0.825\n",
      "Iteration: 230\n",
      "Accuracy: 0.826\n",
      "Iteration: 240\n",
      "Accuracy: 0.829\n",
      "Iteration: 250\n",
      "Accuracy: 0.833\n",
      "Iteration: 260\n",
      "Accuracy: 0.836\n",
      "Iteration: 270\n",
      "Accuracy: 0.842\n",
      "Iteration: 280\n",
      "Accuracy: 0.848\n",
      "Iteration: 290\n",
      "Accuracy: 0.854\n",
      "Iteration: 300\n",
      "Accuracy: 0.86\n",
      "Iteration: 310\n",
      "Accuracy: 0.864\n",
      "Iteration: 320\n",
      "Accuracy: 0.867\n",
      "Iteration: 330\n",
      "Accuracy: 0.87\n",
      "Iteration: 340\n",
      "Accuracy: 0.874\n",
      "Iteration: 350\n",
      "Accuracy: 0.876\n",
      "Iteration: 360\n",
      "Accuracy: 0.877\n",
      "Iteration: 370\n",
      "Accuracy: 0.878\n",
      "Iteration: 380\n",
      "Accuracy: 0.883\n",
      "Iteration: 390\n",
      "Accuracy: 0.887\n",
      "Iteration: 400\n",
      "Accuracy: 0.891\n",
      "Iteration: 410\n",
      "Accuracy: 0.894\n",
      "Iteration: 420\n",
      "Accuracy: 0.899\n",
      "Iteration: 430\n",
      "Accuracy: 0.903\n",
      "Iteration: 440\n",
      "Accuracy: 0.906\n",
      "Iteration: 450\n",
      "Accuracy: 0.91\n",
      "Iteration: 460\n",
      "Accuracy: 0.912\n",
      "Iteration: 470\n",
      "Accuracy: 0.912\n",
      "Iteration: 480\n",
      "Accuracy: 0.912\n",
      "Iteration: 490\n",
      "Accuracy: 0.915\n",
      "Iteration: 500\n",
      "Accuracy: 0.919\n",
      "Iteration: 510\n",
      "Accuracy: 0.923\n",
      "Iteration: 520\n",
      "Accuracy: 0.923\n",
      "Iteration: 530\n",
      "Accuracy: 0.924\n",
      "Iteration: 540\n",
      "Accuracy: 0.927\n",
      "Iteration: 550\n",
      "Accuracy: 0.929\n",
      "Iteration: 560\n",
      "Accuracy: 0.929\n",
      "Iteration: 570\n",
      "Accuracy: 0.934\n",
      "Iteration: 580\n",
      "Accuracy: 0.936\n",
      "Iteration: 590\n",
      "Accuracy: 0.938\n",
      "Iteration: 600\n",
      "Accuracy: 0.942\n",
      "Iteration: 610\n",
      "Accuracy: 0.943\n",
      "Iteration: 620\n",
      "Accuracy: 0.945\n",
      "Iteration: 630\n",
      "Accuracy: 0.948\n",
      "Iteration: 640\n",
      "Accuracy: 0.951\n",
      "Iteration: 650\n",
      "Accuracy: 0.951\n",
      "Iteration: 660\n",
      "Accuracy: 0.952\n",
      "Iteration: 670\n",
      "Accuracy: 0.953\n",
      "Iteration: 680\n",
      "Accuracy: 0.956\n",
      "Iteration: 690\n",
      "Accuracy: 0.956\n",
      "Iteration: 700\n",
      "Accuracy: 0.961\n",
      "Iteration: 710\n",
      "Accuracy: 0.964\n",
      "Iteration: 720\n",
      "Accuracy: 0.965\n",
      "Iteration: 730\n",
      "Accuracy: 0.966\n",
      "Iteration: 740\n",
      "Accuracy: 0.966\n",
      "Iteration: 750\n",
      "Accuracy: 0.966\n",
      "Iteration: 760\n",
      "Accuracy: 0.967\n",
      "Iteration: 770\n",
      "Accuracy: 0.969\n",
      "Iteration: 780\n",
      "Accuracy: 0.969\n",
      "Iteration: 790\n",
      "Accuracy: 0.97\n",
      "Iteration: 800\n",
      "Accuracy: 0.971\n",
      "Iteration: 810\n",
      "Accuracy: 0.973\n",
      "Iteration: 820\n",
      "Accuracy: 0.973\n",
      "Iteration: 830\n",
      "Accuracy: 0.973\n",
      "Iteration: 840\n",
      "Accuracy: 0.974\n",
      "Iteration: 850\n",
      "Accuracy: 0.974\n",
      "Iteration: 860\n",
      "Accuracy: 0.974\n",
      "Iteration: 870\n",
      "Accuracy: 0.974\n",
      "Iteration: 880\n",
      "Accuracy: 0.974\n",
      "Iteration: 890\n",
      "Accuracy: 0.974\n",
      "Iteration: 900\n",
      "Accuracy: 0.974\n",
      "Iteration: 910\n",
      "Accuracy: 0.976\n",
      "Iteration: 920\n",
      "Accuracy: 0.976\n",
      "Iteration: 930\n",
      "Accuracy: 0.977\n",
      "Iteration: 940\n",
      "Accuracy: 0.977\n",
      "Iteration: 950\n",
      "Accuracy: 0.977\n",
      "Iteration: 960\n",
      "Accuracy: 0.977\n",
      "Iteration: 970\n",
      "Accuracy: 0.977\n",
      "Iteration: 980\n",
      "Accuracy: 0.977\n",
      "Iteration: 990\n",
      "Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "# This line executes the gradient descent algorithm to train the neural network using the training data X_train and Y_train,\n",
    "# with a learning rate of 0.10, and for 1000 iterations. It returns the updated parameters W1, b1, W2, and b2.\n",
    "\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3def6755-c2b4-46ef-ac44-194abfc188b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates predictions using the input data and the trained parameters.\n",
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# This function tests a single prediction using the trained parameters on a specific index of the dataset. \n",
    "# It prints the predicted label and the actual label.\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "\n",
    " # This code reshapes the image data to its original 28x28 dimensions and then visualizes it \n",
    " # using matplotlib's imshow function, displaying the grayscale image.\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3ca747-bb19-4f9f-bac8-c7bf7a2fae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function tests the prediction for a specific index in the training dataset using the trained parameters W1, b1, W2, and b2. \n",
    "# It prints the prediction, actual label, and displays the corresponding image.\n",
    "\n",
    "test_prediction(5, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d995d40f-531a-499b-9240-b18d13398e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(133, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbcdd75-b642-43e5-bbf3-d75f8d5471de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374878048780487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code generates predictions for the development dataset and calculates the accuracy of these predictions compared to the actual labels.\n",
    "\n",
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48ec698-e10f-40c8-a3f3-fb034bd7b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test the accuracy of our model code by running our NEW test data\n",
    "\n",
    "data_new = pd.read_csv(r\"C:\\Users\\Home\\Documents\\STUDIUM\\mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b33fbaad-66e6-4cee-831e-a7a6f5279222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df79f91d-51e6-4926-8084-68f31f012dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9',\n",
      "       ...\n",
      "       '28x19', '28x20', '28x21', '28x22', '28x23', '28x24', '28x25', '28x26',\n",
      "       '28x27', '28x28'],\n",
      "      dtype='object', length=785)\n"
     ]
    }
   ],
   "source": [
    "# I'm quickly inspecting my column names and checking the structure of this dataset to make sure it's euqal to my training data\n",
    "print(data_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb23d89-da1e-4679-ba4a-27e36bbe862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on New Dataset: 0.8475\n"
     ]
    }
   ],
   "source": [
    "# We're preprocessing the new dataset in the same way as we did with the training and test datasets\n",
    "# Followed by normalizing pixel values and reshaping features\n",
    "# Making sure the preprocessing steps match what we did before\n",
    "\n",
    "def preprocess_features(data):\n",
    "    X = data.drop(columns=['label']).values  \n",
    "    X = X / 255. \n",
    "    X = X.reshape(X.shape[0], -1)  \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "# Preparing the new dataset features for analysis\n",
    "X_new = preprocess_features(data_new)\n",
    "\n",
    "\n",
    "#  Extracts and preprocesses the labels from the dataset\n",
    "def preprocess_labels(data):\n",
    "    Y = data['label'].values \n",
    "    return Y\n",
    "\n",
    "\n",
    "# Preprocesses the labels of the new dataset\n",
    "Y_new = preprocess_labels(data_new)\n",
    "\n",
    "\n",
    "# Now, using our existing code we run the Data through the Neural Network\n",
    "# Knowing that we previously have defined functions like forward_prop and get_predictions\n",
    "_, _, _, A2_new = forward_prop(W1, b1, W2, b2, X_new.T)\n",
    "predictions_new = get_predictions(A2_new)\n",
    "\n",
    "\n",
    "# Last Step: Evaluating the Accuracy\n",
    "# We compare the predictions with the true labels to calculate the accuracy.\n",
    "accuracy_new = get_accuracy(predictions_new, Y_new)\n",
    "print(\"Accuracy on New Dataset:\", accuracy_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
